{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knows', 'lol']\n",
      "['nw', 'sms', 'urgnt']\n",
      "['abt']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent1 = \"\"\"Just forced myself to eat a slice. I'm really not hungry tho. \n",
    "           Mark is getting worried. He knows I'm sick when I turn down pizza. Lol\"\"\"\n",
    "sent2 = \"I call you later, don't have nw. If urgnt, sms me.\"\n",
    "sent3 = \"Watching a telugu movie..wat abt u?\"\n",
    "def find_unusual_words(text):\n",
    "    text_vocab_set = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab_set = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual_set = text_vocab_set - english_vocab_set\n",
    "    return sorted(unusual_set)\n",
    "\n",
    "print(find_unusual_words(nltk.wordpunct_tokenize(sent1)))\n",
    "#Prints ['knows', 'lol']\n",
    "print(find_unusual_words(nltk.wordpunct_tokenize(sent2)))\n",
    "#Prints ['nw', 'sms', 'urgnt']\n",
    "print(find_unusual_words(nltk.wordpunct_tokenize(sent3)))\n",
    "#Prints ['abt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unusual_words_found = ['knows', 'lol', 'nw', 'sms', 'urgnt', 'abt']\n",
    "from nltk.metrics import edit_distance\n",
    "possible_suggestions={}\n",
    "english_vocab_set = set(w.lower() for w in nltk.corpus.words.words())\n",
    "for unusual_word in unusual_words_found:\n",
    "    for word in english_vocab_set:\n",
    "        dist = edit_distance(unusual_word,word)\n",
    "        if dist<len(unusual_word)/2:\n",
    "            if unusual_word not in possible_suggestions.keys():\n",
    "                possible_suggestions[unusual_word] = [word]\n",
    "            else:\n",
    "                possible_suggestions[unusual_word].append(word)\n",
    "print(possible_suggestions[\"lol\"])\n",
    "\n",
    "#Exercise: Can you refine this further to run in faster and get more appropriate suggestions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_in_text(text):\n",
    "          names = []\n",
    "          words_set = set(i for i in text if i.isalpha())\n",
    "          male_names = nltk.corpus.names.words('male.txt')\n",
    "          female_names = nltk.corpus.names.words('female.txt')\n",
    "          for w in words_set:\n",
    "                    if i in male_names or i in female_names:\n",
    "                              names.append(i)\n",
    "          return names\n",
    "sent1 = \"John and Mary go to the church every Sunday\"\n",
    "sent2 = \"No man has ever seen the dark side of the Moon\"\n",
    "print(names_in_text(word_tokenize(sent1)))\n",
    "print(names_in_text(word_tokenize(sent2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(wn\u001b[38;5;241m.\u001b[39msynsets(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get all lemma names of \"dog\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdog\u001b[49m\u001b[38;5;241m.\u001b[39mlemma_names())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Get all hypernyms of \"dog\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(wn\u001b[38;5;241m.\u001b[39msynset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog.n.01\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mhypernyms())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dog' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "# Get all possible meanings of the word \"dog\n",
    "print(wn.synsets(\"dog\"))\n",
    "# Get all lemma names of \"dog\"\n",
    "print(dog.lemma_names())\n",
    "#Get all hypernyms of \"dog\"\n",
    "print(wn.synset('dog.n.01').hypernyms())\n",
    "# A hypernym is the generic term where as a hyponym is a specific term\n",
    "# For the word dog, the hypernyms are 'canine' and 'domestic_animal'\n",
    "#Get all hyponyms of \"dog\"\n",
    "print(wn.synset('dog.n.01').hyponyms())\n",
    "# some of hyponyms are  \"pug\", \"puppy\", \"lap_dog\", etc..\n",
    "#Get the path similarity between to words - the method returns the shortest path in the taxonomy\n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "print(cat.path_similarity(dog)) #Returns a value between 0 and 1. The higher the number, higher the similarity in path\n",
    "# wu and palmer similarity method. \n",
    "\"\"\" Produces similarity values based on their Least Common Subsumer (most specific ancestor node) and \n",
    "      the maximum depth in the taxonomy\"\"\"\n",
    "cat.wup_similarity(dog)\n",
    "# Get all synonyms of the word 'good'\n",
    "synonyms = []\n",
    "for syn in wn.synsets(\"good\"):\n",
    "          for word in syn.lemmas():\n",
    "                    if word.name() != \"good\":\n",
    "                              synonyms.append(word.name())\n",
    "print(synonyms)\n",
    "# Get all antonyms of the word \"good\"\n",
    "antonyms = []\n",
    "for syn in wn.synsets(\"good\"):\n",
    "          for word in syn.lemmas():\n",
    "                    if word.name() != \"good\" and word.antonyms() :\n",
    "                              antonyms.append( word.antonyms()[0].name())\n",
    "# print(antonyms)\n",
    "# Return the base form (morphy) of a word \n",
    "print(wn.morphy(\"working\" , wn.VERB)) #Prints \"work\"\n",
    "print(wn.morphy(\"denied\" , wn.VERB)) #Prints \"deny\"\n",
    "print(wn.morphy(\"abaci\")) #Prints \"abacus\"\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
