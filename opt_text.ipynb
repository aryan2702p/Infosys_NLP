{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "#read the file \n",
    "#Note: use the correct path of the file depending on your environment\n",
    "file = open(\"sample.txt\",'r') \n",
    "text = ''\n",
    "for i in file.readlines():\n",
    "    text += i\n",
    "# print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove trailing spaces\n",
    "trimmed_text = text.strip()\n",
    "# print(trimmed_text)\n",
    "converted_text = trimmed_text.lower()\n",
    "# print(converted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'history', 'of', 'natural', 'language', 'processing', 'generally', 'started', 'in', 'the', '1950s', ',', 'although', 'work', 'can', 'be', 'found', 'from', 'earlier', 'periods', '.', 'in', '1950', ',', 'alan', 'turing', 'published', 'an', 'article', 'titled', '``', 'intelligence', \"''\", 'which', 'proposed', 'what', 'is', 'now', 'called', 'the', 'turing', 'test', 'as', 'a', 'criterion', 'of', 'intelligence', '.', 'the', 'georgetown', 'experiment', 'in', '1954', 'involved', 'fully', 'automatic', 'translation', 'of', 'more', 'than', 'sixty', 'russian', 'sentences', 'into', 'english', '.', 'the', 'authors', 'claimed', 'that', 'within', 'three', 'or', 'five', 'years', ',', 'machine', 'translation', 'would', 'be', 'a', 'solved', 'problem', '.', '[', '2', ']', 'however', ',', 'real', 'progress', 'was', 'much', 'slower', ',', 'and', 'after', 'the', 'alpac', 'report', 'in', '1966', ',', 'which', 'found', 'that', 'ten-year-long', 'research', 'had', 'failed', 'to', 'fulfill', 'the', 'expectations', ',', 'funding', 'for', 'machine', 'translation', 'was', 'dramatically', 'reduced', '.', 'little', 'further', 'research', 'in', 'machine', 'translation', 'was', 'conducted', 'until', 'the', 'late', '1980s', ',', 'when', 'the', 'first', 'statistical', 'machine', 'translation', 'systems', 'were', 'developed', '.', 'some', 'notably', 'successful', 'natural', 'language', 'processing', 'systems', 'developed', 'in', 'the', '1960s', 'were', 'shrdlu', ',', 'a', 'natural', 'language', 'system', 'working', 'in', 'restricted', '``', 'blocks', 'worlds', \"''\", 'with', 'restricted', 'vocabularies', ',', 'and', 'eliza', ',', 'a', 'simulation', 'of', 'a', 'rogerian', 'psychotherapist', ',', 'written', 'by', 'joseph', 'weizenbaum', 'between', '1964', 'and', '1966.', 'using', 'almost', 'no', 'information', 'about', 'human', 'thought', 'or', 'emotion', ',', 'eliza', 'sometimes', 'provided', 'a', 'startlingly', 'human-like', 'interaction', '.', 'when', 'the', '``', 'patient', \"''\", 'exceeded', 'the', 'very', 'small', 'knowledge', 'base', ',', 'eliza', 'might', 'provide', 'a', 'generic', 'response', ',', 'for', 'example', ',', 'responding', 'to', '``', 'my', 'head', 'hurts', \"''\", 'with', '``', 'why', 'do', 'you', 'say', 'your', 'head', 'hurts', '?', \"''\", '.', 'during', 'the', '1970s', ',', 'many', 'programmers', 'began', 'to', 'write', '``', 'conceptual', 'ontologies', \"''\", ',', 'which', 'structured', 'real-world', 'information', 'into', 'computer-understandable', 'data', '.', 'examples', 'are', 'margie', '(', 'schank', ',', '1975', ')', ',', 'sam', '(', 'cullingford', ',', '1978', ')', ',', 'pam', '(', 'wilensky', ',', '1978', ')', ',', 'talespin', '(', 'meehan', ',', '1976', ')', ',', 'qualm', '(', 'lehnert', ',', '1977', ')', ',', 'politics', '(', 'carbonell', ',', '1979', ')', ',', 'and', 'plot', 'units', '(', 'lehnert', '1981', ')', '.', 'during', 'this', 'time', ',', 'many', 'chatterbots', 'were', 'written', 'including', 'parry', ',', 'racter', ',', 'and', 'jabberwacky', '.', 'up', 'to', 'the', '1980s', ',', 'most', 'natural', 'language', 'processing', 'systems', 'were', 'based', 'on', 'complex', 'sets', 'of', 'hand-written', 'rules', '.', 'starting', 'in', 'the', 'late', '1980s', ',', 'however', ',', 'there', 'was', 'a', 'revolution', 'in', 'natural', 'language', 'processing', 'with', 'the', 'introduction', 'of', 'machine', 'learning', 'algorithms', 'for', 'language', 'processing', '.', 'this', 'was', 'due', 'to', 'both', 'the', 'steady', 'increase', 'in', 'computational', 'power', '(', 'see', 'moore', \"'s\", 'law', ')', 'and', 'the', 'gradual', 'lessening', 'of', 'the', 'dominance', 'of', 'chomskyan', 'theories', 'of', 'linguistics', '(', 'e.g', '.', 'transformational', 'grammar', ')', ',', 'whose', 'theoretical', 'underpinnings', 'discouraged', 'the', 'sort', 'of', 'corpus', 'linguistics', 'that', 'underlies', 'the', 'machine-learning', 'approach', 'to', 'language', 'processing', '.', '[', '3', ']', 'some', 'of', 'the', 'earliest-used', 'machine', 'learning', 'algorithms', ',', 'such', 'as', 'decision', 'trees', ',', 'produced', 'systems', 'of', 'hard', 'if-then', 'rules', 'similar', 'to', 'existing', 'hand-written', 'rules', '.', 'however', ',', 'part-of-speech', 'tagging', 'introduced', 'the', 'use', 'of', 'hidden', 'markov', 'models', 'to', 'natural', 'language', 'processing', ',', 'and', 'increasingly', ',', 'research', 'has', 'focused', 'on', 'statistical', 'models', ',', 'which', 'make', 'soft', ',', 'probabilistic', 'decisions', 'based', 'on', 'attaching', 'real-valued', 'weights', 'to', 'the', 'features', 'making', 'up', 'the', 'input', 'data', '.', 'the', 'cache', 'language', 'models', 'upon', 'which', 'many', 'speech', 'recognition', 'systems', 'now', 'rely', 'are', 'examples', 'of', 'such', 'statistical', 'models', '.', 'such', 'models', 'are', 'generally', 'more', 'robust', 'when', 'given', 'unfamiliar', 'input', ',', 'especially', 'input', 'that', 'contains', 'errors', '(', 'as', 'is', 'very', 'common', 'for', 'real-world', 'data', ')', ',', 'and', 'produce', 'more', 'reliable', 'results', 'when', 'integrated', 'into', 'a', 'larger', 'system', 'comprising', 'multiple', 'subtasks', '.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization using word tokenizer\n",
    "tokenized_list = word_tokenize(converted_text)\n",
    "print(tokenized_list)\n",
    "#Tokenization using word punct tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'history', 'of', 'natural', 'language', 'processing', 'generally', 'started', 'in', 'the', '1950s', ',', 'although', 'work', 'can', 'be', 'found', 'from', 'earlier', 'periods', '.', 'in', '1950', ',', 'alan', 'turing', 'published', 'an', 'article', 'titled', '\"', 'intelligence', '\"', 'which', 'proposed', 'what', 'is', 'now', 'called', 'the', 'turing', 'test', 'as', 'a', 'criterion', 'of', 'intelligence', '.', 'the', 'georgetown', 'experiment', 'in', '1954', 'involved', 'fully', 'automatic', 'translation', 'of', 'more', 'than', 'sixty', 'russian', 'sentences', 'into', 'english', '.', 'the', 'authors', 'claimed', 'that', 'within', 'three', 'or', 'five', 'years', ',', 'machine', 'translation', 'would', 'be', 'a', 'solved', 'problem', '.[', '2', ']', 'however', ',', 'real', 'progress', 'was', 'much', 'slower', ',', 'and', 'after', 'the', 'alpac', 'report', 'in', '1966', ',', 'which', 'found', 'that', 'ten', '-', 'year', '-', 'long', 'research', 'had', 'failed', 'to', 'fulfill', 'the', 'expectations', ',', 'funding', 'for', 'machine', 'translation', 'was', 'dramatically', 'reduced', '.', 'little', 'further', 'research', 'in', 'machine', 'translation', 'was', 'conducted', 'until', 'the', 'late', '1980s', ',', 'when', 'the', 'first', 'statistical', 'machine', 'translation', 'systems', 'were', 'developed', '.', 'some', 'notably', 'successful', 'natural', 'language', 'processing', 'systems', 'developed', 'in', 'the', '1960s', 'were', 'shrdlu', ',', 'a', 'natural', 'language', 'system', 'working', 'in', 'restricted', '\"', 'blocks', 'worlds', '\"', 'with', 'restricted', 'vocabularies', ',', 'and', 'eliza', ',', 'a', 'simulation', 'of', 'a', 'rogerian', 'psychotherapist', ',', 'written', 'by', 'joseph', 'weizenbaum', 'between', '1964', 'and', '1966', '.', 'using', 'almost', 'no', 'information', 'about', 'human', 'thought', 'or', 'emotion', ',', 'eliza', 'sometimes', 'provided', 'a', 'startlingly', 'human', '-', 'like', 'interaction', '.', 'when', 'the', '\"', 'patient', '\"', 'exceeded', 'the', 'very', 'small', 'knowledge', 'base', ',', 'eliza', 'might', 'provide', 'a', 'generic', 'response', ',', 'for', 'example', ',', 'responding', 'to', '\"', 'my', 'head', 'hurts', '\"', 'with', '\"', 'why', 'do', 'you', 'say', 'your', 'head', 'hurts', '?\".', 'during', 'the', '1970s', ',', 'many', 'programmers', 'began', 'to', 'write', '\"', 'conceptual', 'ontologies', '\",', 'which', 'structured', 'real', '-', 'world', 'information', 'into', 'computer', '-', 'understandable', 'data', '.', 'examples', 'are', 'margie', '(', 'schank', ',', '1975', '),', 'sam', '(', 'cullingford', ',', '1978', '),', 'pam', '(', 'wilensky', ',', '1978', '),', 'talespin', '(', 'meehan', ',', '1976', '),', 'qualm', '(', 'lehnert', ',', '1977', '),', 'politics', '(', 'carbonell', ',', '1979', '),', 'and', 'plot', 'units', '(', 'lehnert', '1981', ').', 'during', 'this', 'time', ',', 'many', 'chatterbots', 'were', 'written', 'including', 'parry', ',', 'racter', ',', 'and', 'jabberwacky', '.', 'up', 'to', 'the', '1980s', ',', 'most', 'natural', 'language', 'processing', 'systems', 'were', 'based', 'on', 'complex', 'sets', 'of', 'hand', '-', 'written', 'rules', '.', 'starting', 'in', 'the', 'late', '1980s', ',', 'however', ',', 'there', 'was', 'a', 'revolution', 'in', 'natural', 'language', 'processing', 'with', 'the', 'introduction', 'of', 'machine', 'learning', 'algorithms', 'for', 'language', 'processing', '.', 'this', 'was', 'due', 'to', 'both', 'the', 'steady', 'increase', 'in', 'computational', 'power', '(', 'see', 'moore', \"'\", 's', 'law', ')', 'and', 'the', 'gradual', 'lessening', 'of', 'the', 'dominance', 'of', 'chomskyan', 'theories', 'of', 'linguistics', '(', 'e', '.', 'g', '.', 'transformational', 'grammar', '),', 'whose', 'theoretical', 'underpinnings', 'discouraged', 'the', 'sort', 'of', 'corpus', 'linguistics', 'that', 'underlies', 'the', 'machine', '-', 'learning', 'approach', 'to', 'language', 'processing', '.[', '3', ']', 'some', 'of', 'the', 'earliest', '-', 'used', 'machine', 'learning', 'algorithms', ',', 'such', 'as', 'decision', 'trees', ',', 'produced', 'systems', 'of', 'hard', 'if', '-', 'then', 'rules', 'similar', 'to', 'existing', 'hand', '-', 'written', 'rules', '.', 'however', ',', 'part', '-', 'of', '-', 'speech', 'tagging', 'introduced', 'the', 'use', 'of', 'hidden', 'markov', 'models', 'to', 'natural', 'language', 'processing', ',', 'and', 'increasingly', ',', 'research', 'has', 'focused', 'on', 'statistical', 'models', ',', 'which', 'make', 'soft', ',', 'probabilistic', 'decisions', 'based', 'on', 'attaching', 'real', '-', 'valued', 'weights', 'to', 'the', 'features', 'making', 'up', 'the', 'input', 'data', '.', 'the', 'cache', 'language', 'models', 'upon', 'which', 'many', 'speech', 'recognition', 'systems', 'now', 'rely', 'are', 'examples', 'of', 'such', 'statistical', 'models', '.', 'such', 'models', 'are', 'generally', 'more', 'robust', 'when', 'given', 'unfamiliar', 'input', ',', 'especially', 'input', 'that', 'contains', 'errors', '(', 'as', 'is', 'very', 'common', 'for', 'real', '-', 'world', 'data', '),', 'and', 'produce', 'more', 'reliable', 'results', 'when', 'integrated', 'into', 'a', 'larger', 'system', 'comprising', 'multiple', 'subtasks', '.']\n"
     ]
    }
   ],
   "source": [
    "punct_tokenized_list = wordpunct_tokenize(converted_text)\n",
    "print(punct_tokenized_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'most', 'developed', 'models', 'errors', 'example', 'increasingly', 'moore', 'published', 'blocks', 'almost', 'base', 'on', 'grammar', 'earlier', 'started', 'response', 'introduction', 'russian', 'problem', 'introduced', 'successful', 'part-of-speech', 'chomskyan', 'the', '(', 'worlds', 'patient', 'this', 'hard', '1950', 'language', 'gradual', 'tagging', 'interaction', 'lessening', 'restricted', 'or', 'including', 'based', 'solved', 'can', 'turing', '1970s', 'than', 'when', 'e.g', 'were', 'sort', 'simulation', 'multiple', 'alan', ']', 'with', '1977', 'joseph', 'human', 'intelligence', 'schank', 'whose', 'results', 'contains', 'written', 'criterion', 'corpus', 'machine-learning', 'working', 'integrated', 'titled', 'complex', 'both', 'was', 'sometimes', 'which', '2', 'steady', 'however', '1966', 'dramatically', '1975', 'to', 'authors', 'rogerian', 'produced', 'comprising', 'years', 'reliable', 'rely', '1960s', 'using', 'provided', 'qualm', '1950s', '.', 'carbonell', 'linguistics', 'soft', 'responding', '1978', 'see', 'politics', 'funding', 'psychotherapist', 'real', 'transformational', 'about', 'theoretical', 'expectations', 'began', 'would', '1976', 'dominance', 'hand-written', 'small', 'cullingford', 'generic', 'due', 'has', '?', 'write', 'although', 'alpac', 'system', 'some', 'in', 'machine', 'theories', 'existing', 'make', 'racter', 'say', 'ten-year-long', 'involved', 'very', 'real-world', 'no', 'learning', 'speech', 'exceeded', 'claimed', 'data', '``', 'human-like', 'input', 'conducted', 'that', 'within', 'test', 'making', 'sets', 'trees', 'a', 'meehan', 'why', 'there', 'hidden', 'increase', 'robust', 'from', 'research', 'first', 'until', 'jabberwacky', 'talespin', 'computational', 'english', 'parry', 'found', 'more', 'wilensky', 'five', 'focused', 'produce', 'underpinnings', 'discouraged', 'my', 'lehnert', 'features', 'you', 'computer-understandable', 'slower', 'cache', 'into', 'progress', 'earliest-used', 'decisions', 'your', 'shrdlu', 'fulfill', 'periods', 'are', 'head', 'of', 'structured', 'law', '1981', 'reduced', 'algorithms', 'startlingly', 'automatic', 'systems', 'time', 'chatterbots', 'little', 'approach', 'decision', 'recognition', 'do', 'much', 'plot', 'similar', 'probabilistic', 'upon', 'is', 'natural', 'such', 'real-valued', 'if-then', 'article', 'underlies', 'especially', 'as', 'attaching', 'unfamiliar', '1980s', '1979', 'late', \"'s\", 'larger', '1966.', 'vocabularies', 'margie', ',', 'georgetown', 'hurts', 'pam', 'power', 'translation', 'subtasks', 'notably', 'weizenbaum', 'might', 'and', 'by', 'up', '3', 'an', 'processing', 'provide', 'revolution', 'weights', 'called', '1954', 'conceptual', 'eliza', 'work', 'knowledge', 'starting', 'failed', ')', 'what', 'for', 'now', 'report', 'sixty', 'given', 'generally', '1964', 'units', 'use', 'sentences', 'sam', 'markov', 'thought', 'had', 'examples', 'history', \"''\", 'proposed', 'further', 'statistical', 'between', 'be', 'rules', 'experiment', 'fully', 'after', 'programmers', 'ontologies', 'common', 'three', 'emotion', 'during', 'information', 'many', '['}\n"
     ]
    }
   ],
   "source": [
    "#get vocabulary\n",
    "vocab_set = set(tokenized_list)\n",
    "print(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'developed', 'models', 'errors', 'example', 'increasingly', 'moore', 'published', 'blocks', 'almost', 'base', 'grammar', 'earlier', 'started', 'response', 'introduction', 'russian', 'problem', 'introduced', 'successful', 'part-of-speech', 'chomskyan', '(', 'worlds', 'patient', 'hard', '1950', 'language', 'gradual', 'tagging', 'interaction', 'lessening', 'restricted', 'including', 'based', 'solved', 'turing', '1970s', 'e.g', 'sort', 'simulation', 'multiple', 'alan', ']', '1977', 'joseph', 'human', 'intelligence', 'schank', 'whose', 'results', 'contains', 'written', 'criterion', 'corpus', 'machine-learning', 'working', 'integrated', 'complex', 'titled', 'sometimes', '2', 'steady', 'however', '1966', 'dramatically', '1975', 'authors', 'rogerian', 'produced', 'comprising', 'years', 'reliable', 'rely', '1960s', 'using', 'provided', 'qualm', '1950s', '.', 'carbonell', 'linguistics', 'soft', 'responding', '1978', 'see', 'politics', 'funding', 'psychotherapist', 'real', 'transformational', 'theoretical', 'expectations', 'began', 'would', '1976', 'dominance', 'hand-written', 'small', 'cullingford', 'generic', 'due', '?', 'write', 'although', 'alpac', 'system', 'theories', 'machine', 'existing', 'make', 'racter', 'say', 'ten-year-long', 'involved', 'real-world', 'learning', 'speech', 'exceeded', 'claimed', 'data', '``', 'human-like', 'input', 'conducted', 'within', 'test', 'making', 'sets', 'trees', 'meehan', 'hidden', 'increase', 'robust', 'research', 'first', 'jabberwacky', 'talespin', 'computational', 'english', 'parry', 'found', 'wilensky', 'focused', 'five', 'produce', 'underpinnings', 'discouraged', 'lehnert', 'features', 'computer-understandable', 'slower', 'cache', 'progress', 'decisions', 'shrdlu', 'fulfill', 'periods', 'earliest-used', 'head', 'structured', 'law', '1981', 'reduced', 'algorithms', 'startlingly', 'automatic', 'systems', 'time', 'chatterbots', 'little', 'approach', 'decision', 'recognition', 'plot', 'much', 'similar', 'probabilistic', 'upon', 'natural', 'real-valued', 'if-then', 'article', 'underlies', 'especially', 'attaching', 'unfamiliar', '1980s', '1979', 'late', \"'s\", 'larger', '1966.', 'vocabularies', 'margie', ',', 'georgetown', 'hurts', 'pam', 'power', 'translation', 'subtasks', 'notably', 'weizenbaum', 'might', '3', 'weights', 'revolution', 'processing', 'provide', 'called', '1954', 'conceptual', 'eliza', 'work', 'knowledge', 'starting', 'failed', ')', 'report', 'sixty', 'given', 'generally', '1964', 'units', 'use', 'sentences', 'sam', 'markov', 'thought', 'examples', 'history', \"''\", 'proposed', 'statistical', 'rules', 'experiment', 'fully', 'programmers', 'ontologies', 'common', 'three', 'emotion', 'information', 'many', '['}\n"
     ]
    }
   ],
   "source": [
    "#remove stop words\n",
    "set_wo_stopwords = vocab_set - set(stopwords.words(\"english\"))\n",
    "print(set_wo_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "set_wo_punctuation = set_wo_stopwords - set(punctuation)\n",
    "# print(set_wo_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('developed', 'models'), ('models', 'errors'), ('errors', 'example'), ('example', 'increasingly'), ('increasingly', 'moore'), ('moore', 'published'), ('published', 'blocks'), ('blocks', 'almost'), ('almost', 'base'), ('base', 'grammar'), ('grammar', 'earlier'), ('earlier', 'started'), ('started', 'response'), ('response', 'introduction'), ('introduction', 'russian'), ('russian', 'problem'), ('problem', 'introduced'), ('introduced', 'successful'), ('successful', 'part-of-speech'), ('part-of-speech', 'chomskyan'), ('chomskyan', 'worlds'), ('worlds', 'patient'), ('patient', 'hard'), ('hard', '1950'), ('1950', 'language'), ('language', 'gradual'), ('gradual', 'tagging'), ('tagging', 'interaction'), ('interaction', 'lessening'), ('lessening', 'restricted'), ('restricted', 'including'), ('including', 'based'), ('based', 'solved'), ('solved', 'turing'), ('turing', '1970s'), ('1970s', 'e.g'), ('e.g', 'sort'), ('sort', 'simulation'), ('simulation', 'multiple'), ('multiple', 'alan'), ('alan', '1977'), ('1977', 'joseph'), ('joseph', 'human'), ('human', 'intelligence'), ('intelligence', 'schank'), ('schank', 'whose'), ('whose', 'results'), ('results', 'contains'), ('contains', 'written'), ('written', 'criterion'), ('criterion', 'corpus'), ('corpus', 'machine-learning'), ('machine-learning', 'working'), ('working', 'integrated'), ('integrated', 'complex'), ('complex', 'titled'), ('titled', 'sometimes'), ('sometimes', '2'), ('2', 'steady'), ('steady', 'however'), ('however', '1966'), ('1966', 'dramatically'), ('dramatically', '1975'), ('1975', 'authors'), ('authors', 'rogerian'), ('rogerian', 'produced'), ('produced', 'comprising'), ('comprising', 'years'), ('years', 'reliable'), ('reliable', 'rely'), ('rely', '1960s'), ('1960s', 'using'), ('using', 'provided'), ('provided', 'qualm'), ('qualm', '1950s'), ('1950s', 'carbonell'), ('carbonell', 'linguistics'), ('linguistics', 'soft'), ('soft', 'responding'), ('responding', '1978'), ('1978', 'see'), ('see', 'politics'), ('politics', 'funding'), ('funding', 'psychotherapist'), ('psychotherapist', 'real'), ('real', 'transformational'), ('transformational', 'theoretical'), ('theoretical', 'expectations'), ('expectations', 'began'), ('began', 'would'), ('would', '1976'), ('1976', 'dominance'), ('dominance', 'hand-written'), ('hand-written', 'small'), ('small', 'cullingford'), ('cullingford', 'generic'), ('generic', 'due'), ('due', 'write'), ('write', 'although'), ('although', 'alpac'), ('alpac', 'system'), ('system', 'theories'), ('theories', 'machine'), ('machine', 'existing'), ('existing', 'make'), ('make', 'racter'), ('racter', 'say'), ('say', 'ten-year-long'), ('ten-year-long', 'involved'), ('involved', 'real-world'), ('real-world', 'learning'), ('learning', 'speech'), ('speech', 'exceeded'), ('exceeded', 'claimed'), ('claimed', 'data'), ('data', '``'), ('``', 'human-like'), ('human-like', 'input'), ('input', 'conducted'), ('conducted', 'within'), ('within', 'test'), ('test', 'making'), ('making', 'sets'), ('sets', 'trees'), ('trees', 'meehan'), ('meehan', 'hidden'), ('hidden', 'increase'), ('increase', 'robust'), ('robust', 'research'), ('research', 'first'), ('first', 'jabberwacky'), ('jabberwacky', 'talespin'), ('talespin', 'computational'), ('computational', 'english'), ('english', 'parry'), ('parry', 'found'), ('found', 'wilensky'), ('wilensky', 'focused'), ('focused', 'five'), ('five', 'produce'), ('produce', 'underpinnings'), ('underpinnings', 'discouraged'), ('discouraged', 'lehnert'), ('lehnert', 'features'), ('features', 'computer-understandable'), ('computer-understandable', 'slower'), ('slower', 'cache'), ('cache', 'progress'), ('progress', 'decisions'), ('decisions', 'shrdlu'), ('shrdlu', 'fulfill'), ('fulfill', 'periods'), ('periods', 'earliest-used'), ('earliest-used', 'head'), ('head', 'structured'), ('structured', 'law'), ('law', '1981'), ('1981', 'reduced'), ('reduced', 'algorithms'), ('algorithms', 'startlingly'), ('startlingly', 'automatic'), ('automatic', 'systems'), ('systems', 'time'), ('time', 'chatterbots'), ('chatterbots', 'little'), ('little', 'approach'), ('approach', 'decision'), ('decision', 'recognition'), ('recognition', 'plot'), ('plot', 'much'), ('much', 'similar'), ('similar', 'probabilistic'), ('probabilistic', 'upon'), ('upon', 'natural'), ('natural', 'real-valued'), ('real-valued', 'if-then'), ('if-then', 'article'), ('article', 'underlies'), ('underlies', 'especially'), ('especially', 'attaching'), ('attaching', 'unfamiliar'), ('unfamiliar', '1980s'), ('1980s', '1979'), ('1979', 'late'), ('late', \"'s\"), (\"'s\", 'larger'), ('larger', '1966.'), ('1966.', 'vocabularies'), ('vocabularies', 'margie'), ('margie', 'georgetown'), ('georgetown', 'hurts'), ('hurts', 'pam'), ('pam', 'power'), ('power', 'translation'), ('translation', 'subtasks'), ('subtasks', 'notably'), ('notably', 'weizenbaum'), ('weizenbaum', 'might'), ('might', '3'), ('3', 'weights'), ('weights', 'revolution'), ('revolution', 'processing'), ('processing', 'provide'), ('provide', 'called'), ('called', '1954'), ('1954', 'conceptual'), ('conceptual', 'eliza'), ('eliza', 'work'), ('work', 'knowledge'), ('knowledge', 'starting'), ('starting', 'failed'), ('failed', 'report'), ('report', 'sixty'), ('sixty', 'given'), ('given', 'generally'), ('generally', '1964'), ('1964', 'units'), ('units', 'use'), ('use', 'sentences'), ('sentences', 'sam'), ('sam', 'markov'), ('markov', 'thought'), ('thought', 'examples'), ('examples', 'history'), ('history', \"''\"), (\"''\", 'proposed'), ('proposed', 'statistical'), ('statistical', 'rules'), ('rules', 'experiment'), ('experiment', 'fully'), ('fully', 'programmers'), ('programmers', 'ontologies'), ('ontologies', 'common'), ('common', 'three'), ('three', 'emotion'), ('emotion', 'information'), ('information', 'many')]\n"
     ]
    }
   ],
   "source": [
    "#bigrams\n",
    "from nltk import ngrams\n",
    "bigrams = ngrams(set_wo_punctuation, 2)\n",
    "\n",
    "print(list(bigrams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\91827\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\91827\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Barack/NNP)\n",
      "  (PERSON Hussein/NNP Obama/NNP)\n",
      "  (/(\n",
      "  born/VBN\n",
      "  August/NNP\n",
      "  4/CD\n",
      "  ,/,\n",
      "  1961/CD\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  (GPE American/JJ)\n",
      "  politician/NN\n",
      "  who/WP\n",
      "  served/VBD\n",
      "  as/IN\n",
      "  the/DT\n",
      "  44th/CD\n",
      "  President/NNP\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  from/IN\n",
      "  January/NNP\n",
      "  20/CD\n",
      "  ,/,\n",
      "  2009/CD\n",
      "  ,/,\n",
      "  to/TO\n",
      "  January/NNP\n",
      "  20/CD\n",
      "  ,/,\n",
      "  2017/CD\n",
      "  ./.\n",
      "  A/DT\n",
      "  member/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Democratic/NNP Party/NNP)\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  the/DT\n",
      "  first/JJ\n",
      "  (ORGANIZATION African/JJ American/NNP)\n",
      "  to/TO\n",
      "  assume/VB\n",
      "  the/DT\n",
      "  presidency/NN\n",
      "  and/CC\n",
      "  previously/RB\n",
      "  served/VBD\n",
      "  as/IN\n",
      "  a/DT\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  Senator/NNP\n",
      "  from/IN\n",
      "  (GPE Illinois/NNP)\n",
      "  (/(\n",
      "  2005-2008/JJ\n",
      "  )/)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "barack = \"\"\"Barack Hussein Obama (born August 4, 1961) is an American politician \n",
    "who served as the 44th President of the United States from January 20, 2009, to January 20, 2017.\n",
    "A member of the Democratic Party, he was the first African American to assume the presidency\n",
    "and previously served as a United States Senator from Illinois (2005-2008).\"\"\"\n",
    "tokenised_barack = word_tokenize(barack)\n",
    "pos_list = pos_tag(tokenised_barack)\n",
    "print(ne_chunk(pos_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Person Barack/NNP Hussein/NNP Obama/NNP)\n",
      "  (/(\n",
      "  born/VBN\n",
      "  (Date August/NNP 4/CD ,/, 1961/CD)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  American/JJ\n",
      "  politician/NN\n",
      "  who/WP\n",
      "  served/VBD\n",
      "  as/IN\n",
      "  the/DT\n",
      "  44th/CD\n",
      "  (Person President/NNP)\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Place United/NNP States/NNPS)\n",
      "  from/IN\n",
      "  (Date January/NNP 20/CD ,/, 2009/CD)\n",
      "  ,/,\n",
      "  to/TO\n",
      "  (Date January/NNP 20/CD ,/, 2017/CD)\n",
      "  ./.\n",
      "  A/DT\n",
      "  member/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Person Democratic/NNP Party/NNP)\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  the/DT\n",
      "  first/JJ\n",
      "  African/JJ\n",
      "  (Person American/NNP)\n",
      "  to/TO\n",
      "  assume/VB\n",
      "  the/DT\n",
      "  presidency/NN\n",
      "  and/CC\n",
      "  previously/RB\n",
      "  served/VBD\n",
      "  as/IN\n",
      "  a/DT\n",
      "  (Place United/NNP States/NNPS)\n",
      "  (Person Senator/NNP)\n",
      "  from/IN\n",
      "  (Person Illinois/NNP)\n",
      "  (/(\n",
      "  2005-2008/JJ\n",
      "  )/)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpParser\n",
    "grammar = r\"\"\"Place: {<NNP><NNPS>+}\n",
    "           Date: {<NNP><CD><,><CD>}\n",
    "           Person: {<NNP>+}\n",
    "           \"\"\"\n",
    "tokenised_barack = word_tokenize(barack)\n",
    "pos_list = pos_tag(tokenised_barack)\n",
    "regParser = RegexpParser(grammar)\n",
    "reg_lines = regParser.parse(pos_list)\n",
    "print(reg_lines) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
